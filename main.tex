\documentclass{aicom2e}
\usepackage{amsmath}
\usepackage[algo2e,ruled,vlined,linesnumbered]{algorithm2e}
\usepackage[active]{srcltx}


%\usepackage{amsthm, amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{latexsym}
\usepackage{colortbl}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{caption}
\usepackage{subfig}
\usepackage{float}
\usepackage{xcolor}
\usepackage{pslatex}
\usepackage{eso-pic}
\usepackage[bottom]{footmisc}
\usepackage{url}
\usepackage{etex}


\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newcommand{\kgs}{$k$-goal search}
\newcommand{\astar}{A$^*$}
\newcommand{\tuple}[1]{\ensuremath{\left \langle #1 \right \rangle }}
\newcommand{\open}{\textsc{Open}}
%\newenvironment{proof}{\noindent{\bf Proof:~~}}{\qed}

\begin{document}
\begin{frontmatter}                           % The preamble begins here.
%
%\pretitle{Pretitle}
\title{Shortest Path for K Goals}
% \runningtitle{Running title}
%\subtitle{Subtitle}
\maketitle
%
\author[]{Meir Goldenberg}
\address{Lev Academic Center\\ Jerusalem, Israel\\
	E-mail: mgoldenbe@gmail.com}
\author[]{Roni Stern}
\address{Ben Gurion University of the Negev\\ Be'er Sheva, Israel\\
E-mail: roni.stern@gmail.com}
\author[]{Ariel Felner}
\address{Ben Gurion University of the Negev\\ Be'er Sheva, Israel\\
	E-mail: felner@bgu.ac.il}

\begin{abstract}
Abstract...

\end{abstract}

\begin{keyword}
artificial intelligence\sep AI\sep Heuristic Search
\end{keyword}
%
\end{frontmatter}

\section*{Introduction}


\section{Background and Problem Definition}

%In this section, we formally define the $k$-goal search problem.
In this section we provide relevant background and formally define the \kgs\ problem. 
Let $G=(V,E,w)$ be a weighted graph, where $w:E\rightarrow \mathbb{R}^+$ be the weight function, i.e., for an edge $e\in E$ the value $w(e)$ is its weight. 
The shortest path problem (SPP) is the problem of finding the lowest cost path in $G$ from a given start vertex $s$ to a goal vertex $g$. 

SPP has been well-studied in the literature. A popular framework for solving SPP is Best-first search (BFS). There are many path-finding algorithms that are based on BFS, including classical SPP algorithms like Dijkstra's algorithm~\cite{} and \astar{}. 
    While BFS has many variants, Algorithm~\ref{alg:bfs} provides a high-level pseudo-code for BFS. 


[[TODO: Background on BFS and on \astar{}. Talking also about admissible heuristics]]


\begin{algorithm2e}[t!]
\begin{footnotesize}
\SetAlgoLined 
\SetKwBlock{BFS}{best-first-search(start state $s$, goal state $g$)}{end} \BFS{
    Bla\\
    \open{}~$\gets\{s\}$; \\
    \While {\open{} $\neq \emptyset$} {
        $best \gets \texttt{ChooseNode}(\open{})$ \nllabel{line:open:chooseNode}\\
        Remove $best$ from \open{}\\
                \lIf {$best$ is a goal}{\Return $best$}
        \For{$n \in neighbors(best)$}{
            Add $n$ to \open{}\\
        }
    }
} 
\label{alg:bfs}
\end{footnotesize}
\end{algorithm2e}




The $\texttt{ChooseNode}$ function (line~\ref{line:open:chooseNode} in Alg.~\ref{alg:bfs}) is often implemented by defining a node evaluation function $F$, such that 
the chosen node is the one with the minimal $F$ value. For example, Dijsktra's algorithm is a BFS in which $F=g$, and \astar{} is a BFS in which $F=f=g+h$. 




The $k$-goal search problem can be viewed as a generalization of SPP, and is defined as follows. 

\begin{definition}[$k$-goal search]
Given a weighted graph $G$, a start vertex $s\in V$, and $k$ goal vertices 
$g_1, g_2,\ldots g_k\in V$, the task is to find $k$ paths $p_1,\ldots p_k$ 
such that for every $i\in [1,k]$ it holds that $p_i$ is a lowest-cost path from $s$ to $g_i$. 
\end{definition}

% k searches independentaly
Clearly, SPP is a special case of \kgs\ with $k=1$. A trivial solution to the \kgs\ problem is to consider it as $k$ independent shortest path problem,
and use a SPP algorithm such as Dijkstra's algorithm~\cite{} or \astar{}~\cite{}. 
In this work we explore different approaches for solving the \kgs\ problem that try to reuse information between the $k$ tasks. 


\section{One BFS for $k$-Goal Search}

In this section we explore how to find solve the \kgs{} using a single BFS. This is motivated by the understanding that performing $k$ different searches may
explore the same node multiple times. 
To extend BFS to solve the \kgs\ problem, the following algorithmic components 
must be modified. 

\begin{itemize}
    \item {\bf Information stored per node.} When searching for a single lowest-cost path, every node in \open{} stored two values: the $g$-value and the $h$-value. To extend BFS to solve the \kgs\ problem, we store for every node $k+1$ values: the $g$-value and the $h$-value for each of the $k$ goals. Consequently, when every a node is generated, the heuristic funciton must be computed for each of the $k$ goal.
    \item {\bf Stopping condition.} When one of the goal vertices is expanded, the found path to that goal is returned to the user. However, the search does not halt until lowest-cost paths to all $k$ are found. Therefore, after a path to a goal is found the search continues, expanding the found goal vertex and inserting its children to \open . 
\end{itemize}
Note that after finding a lowest-cost path to a goal $g_i$ there is no point in
computing the $h$-value for it. 

In addition to these easy-to-implement changes, 
there is the question of which node to choose to expand in every iteration. 
In \astar{}, the node with the minimal $f=g+h$ value is chosen. 
In \kgs{}, however, there are $k$ heuristic values for each node $n$, $h_1(n),\ldots,h_k(n)$, 
which are the heuristic estimate of the cost to get from $n$ to goal $g_1,\ldots,g_k$, respectively.  
Consequently, each node has multiple  $f$ values, $f_1(n),\ldots,f_k(n)$, one per goal. 
This raises the question of how to define the node evaluation function $F$ for \kgs{}, 
i.e,. which node to choose from \open{} in every iteration when solving the \kgs{} problem?

We discuss next the following two options. 
\begin{itemize}
 \item {\bf Min-$f$.} $F_{min}(n)=\min_{i\in [1,k]}f_i(n)$. 
 \item {\bf Max-$f$.} $F_{max}(n)=\max_{i\in [1,k]}f_i(n)$. 
 %\item {\bf Random-$f$.} $F(n)=ChooseRandom(f_1(n),\ldots,f_k(n))$. 
\end{itemize}

\begin{theorem}[Min-$f$ is admissible]
Using an admissible heuristic, 
When using an admissible heursitic and running a BFS that uses $F_{min}$ as an evaluation function,
then when each goal $g_i$ is expanded for the firts time it is guaranteed that the lowest-cost path to $g_i$ has been found. 
\label{the:min-f}
\end{theorem}
 \begin{proof}
 TODO
 \end{proof}
 
 \begin{figure}
 \includegraphics[width=\columnwidth]{max-bad_cropped.pdf}      
 \caption{An example of where using Max-$f$ returns a non-optimal solution. In this example, 
 using Max-$f$ will results in the following expansion order: $S$, $B$, $G_1$. 
 Thus, when $G_1$ is expanded, the best path known to it costs 25, while a 
 better path to it goes through $A$ and costs only 10.}
 \label{fig:max-bad}
 \end{figure}
 
 When using Max-$f$, however, expanding a goal $g_i$ does not guarantee
 that the optimal solution to $g_i$ has been found. As a counter-example, consider 
 the graph in Figure~\ref{fig:max-bad}.
 In this example, using Max-$f$ will result in the following expansion order: $S$, $B$, and then $G_1$. 
 At this stage, we expanded one of the goals -- $G_1$ -- while the best path found so far to it goes through $B$ and costs 40. However, a better path to it is through $A$, which costs only 10.
 
 
 Of course, one may still use Max-$f$ as an anytime algorithm continuing the search and looking for better path to the previoulsy expanded goals. 
 
 [[TODO: What is a good stopping condition for this option?]]
 
 
 
 The observant reader may have noticed that the heuristic function in the example in Figure~\ref{fig:max-bad} is inconsistent: $h_2(A)=50$ while its child, $G_1$, which is connected to it via an edge of cost 5, has $h_2(G_1)=20$. If $h$ was consistent the $h_2(A)-c(A,G_1)\leq h_2(G_1)$, where e$c(A,G_1)$ is the cost of the edge between $A$ and $G_1$. This leads to the following theorem.
 
 
\begin{theorem}[Max-$f$ is admissible if $h$ is consistent]
If $G$ is undirected and $h$ is admissible and consistent, 
then when running a BFS that uses Max-$f$ as an evaluation function,
it holds that whenever a goal is expanded then the lowest-cost path to it has been found. 
\label{the:max-f}
\end{theorem}
 \begin{proof}
 Assume by negation that Theorem~\ref{the:max-f} is not correct. This means
 that there is a case where a goal $G_i$ is expanded while $g(G_i)$ is not optimal. 
 Since we are running a BFS, this means that there exists a node $n\in OPEN$ that
 in the optimal path to $G_i$ and for which $g(n)=g^*(n)$ and 
 \begin{equation}
     g(n)+h_i^*(n) < g(G_i)
    \label{eq:not-optimal}
 \end{equation}
 
 Now, since $G_i$ was chosen for expansion and not $n$, it holds that 
\[                F_{max}(n)                     > F_{max}(G_i) \] 

 \[ \rightarrow    g(n)+\max_j h_j(n)              > g(G_i) \max_j' h_{j'}(G_i) \]
 
 \[ \rightarrow \exists l   g(n)+h_l(n)            > g(G_i)+h_l(G_i) \]
 
 \[ \rightarrow \exists l   g(n)+h_l(n)-h_l(G_i)   > g(G_i) \]
 
 
 \[ \rightarrow \exists l   g(n)+h_l(n)-h_l(G_i)   > g(n)+h^*_i(n) ~~~ (\ref{eq:not-optimal})\]
 
\[ \rightarrow \exists l   h_l(n)-h_l(G_i)   > h^*_i(n) \]

\[ \rightarrow \exists l   h_l(n)   > h^*_i(n)+h_l(G_i) \]


\begin{align}
TEST & t 
\end{align}

 \begin{equation}
     \exists l   h_l(n)   > h^*_i(n)+h_l(G_i)
    \label{eq:triangle-violated}
 \end{equation}

Observe that $h^*_i(n)$ is exactly the lowest cost path from $i$ to $G_i$. 
Since $G$ is undirected, then it is also equal to the lowest-cost path from $G_i$ 
to $n$. Thus, Equation~\ref{eq:triangle-violated} directly contradicts the assumption
that $h$ is consistent: it shows that $h^*_i(n)+h_l(G_i)$ is a better heuristic 
to the path from $n$ to $G_l$ than $h_l(n)$. Thus, if the heurisic is consistent
then when a goal is expanded then we have the optimal path to it. 
 \end{proof} 


\subsection{Runtime Analysis}
% Analysis
Now, we compare the the two approaches descibed bove -- $k$ separate SPP problems or one BFS to return all the $k$ paths. 
It is common to estimate the runtime of BFS by counting the number of nodes that are expanded until the goal is found. However, we can show that both approaches will expand the same set of nodes.  However, the computation done per node is different. 

[[Here will come Ariel's analysis of the runtime]]




\section{Experimental Results}
[[Here will come experimental results]]

\subsection*{Related work}

There are several well-studied graph problems that are related to $k$-goal search. In the traveling salesman problem (TSP), we aim to find a shortest path that passes through a set of vertices. 
...

\section{Conclusion and Future Work}

% \begin{figure}[!htbp]
%   \centering
%   \includegraphics[width=1\hsize]{filename.eps}
%   \caption{caption} \label{fig:label}
% \end{figure}

\section*{Acknowledgements}
Thanks!

\bibliographystyle{abbrv}
\bibliography{library}

\end{document}
